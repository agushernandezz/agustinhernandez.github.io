<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link href="output.css" rel="stylesheet">
    <link rel="canonical" href="https://agushernandezz.github.io/agustinhernandez.github.io/">
    <title>Agustin Hernandez | Student @ UBA</title>
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    <meta name="og:url" content="https://agushernandezz.github.io/agustinhernandez.github.io/">
    <meta name="og:site_name" content="Agustin Hernandez | Student @ UBA">
    <meta name="og:description" content="I'm a 4th year double degree student in Computer Science and Data Science at the University of Buenos Aires. Learn more about me.">
    <meta name="og:title" content="Agustin Hernandez | Student @ UBA">
    <meta name="og:image" content="https://agushernandezz.github.io/agustinhernandez.github.io/images/profile.jpg">
    <meta name="og:type" content="software">
    <meta name="description" content="I'm a 4th year double degree student in Computer Science and Data Science at the University of Buenos Aires. Learn more about me.">
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5T8QWMR');</script>
    <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
    </head>
<body class="bg-white text-gray-700 font-sans lg:max-w-5xl lg:mt-14 m-2 p-4 lg:m-auto">
    <div class="lg:flex lg:max-w-7xl lg:mx-auto">
        <aside class="lg:w-60 lg:fixed">
            <div class="p-4 text-center">
                <img src="image.png" alt="avatar" class="rounded-[3rem] mx-auto mt-8 w-[190px]">
                <h1 class="text-3xl font-[550] mt-4 text-sky-600">Agustin Hernandez</h1>
                <p class="text-gray-600  font-mono text-sm mt-2">me [at] zhyncs.com</p>
                <div class="mt-4 flex justify-center space-x-4">
                    <a href="https://scholar.google.com/citations?user=SmZ0KcYAAAAJ&hl=en" class="text-sky-500 hover:text-sky-700">
                        <i class="ai ai-google-scholar text-xl"></i>
                    </a>
                    <a href="https://github.com/zhyncs" class="text-sky-500 hover:text-sky-700">
                        <i class="fab fa-github text-xl"></i>
                    </a>
                    <a href="https://www.linkedin.com/in/zhyncs" class="text-sky-500 hover:text-sky-700">
                        <i class="fab fa-linkedin text-xl"></i>
                    </a>
                    <a href="https://x.com/zhyncs42" class="text-sky-500 hover:text-sky-700">
                        <i class="fab fa-x-twitter text-xl"></i>
                    </a>
                </div>
            </div>
        </aside>

        <div class="lg:hidden border-t border-gray-200"></div>

        <!-- Main Content -->
        <main class="lg:ml-52 flex-1">
            <div class="container mx-auto px-4 py-8 lg:w-[650px]">
                <!-- About Me -->
                <h2 class="text-xl font-[550] mt-8 mb-4 text-sky-600">About Me</h2>
                <p class="mb-4">
                    I am a Lead Software Engineer on the model performance team at Baseten, with over five years of professional software engineering experience. I previously worked at Baidu and Meituan, two of China's top five technology companies by market capitalization. I specialize in inference optimization for search and recommendation ranking models, as well as large language model inference acceleration.
                </p>
                <p class="mb-4">
                    I serve as a team member at <a href="https://lmsys.org/about" class="text-sky-500 hover:underline">LMSYS Org</a>. As the core developer at <a href="https://github.com/sgl-project" class="text-sky-500 hover:underline">SGLang team</a>, I am one of the top three contributors to the <a href="https://github.com/sgl-project/sglang" class="text-sky-500 hover:underline">SGLang project</a>, responsible for its development and maintenance.
                </p>
                <p class="mb-4">
                    I work closely with <a href="https://lmzheng.net" class="text-sky-500 hover:underline">Lianmin Zheng</a> and <a href="https://sites.google.com/view/yingsheng/home" class="text-sky-500 hover:underline">Ying Sheng</a> on the <a href="https://github.com/sgl-project/sglang" class="text-sky-500 hover:underline">SGLang</a> project, while also working closely with <a href="https://homes.cs.washington.edu/~zhye" class="text-sky-500 hover:underline">Zihao Ye</a> on the <a href="https://github.com/flashinfer-ai/flashinfer" class="text-sky-500 hover:underline">FlashInfer</a> project.
                </p>
                <p class="mb-4">
                    The best way to contact me is via the <a href="https://slack.sglang.ai" class="text-sky-500 hover:underline">SGLang Slack</a>. We're looking for open-source enthusiasts and learners to help grow the SGLang project and community. If you want to chat on Google Meet, schedule a time through my Calendly. Please include <strong>a brief self-introduction and your discussion topic</strong> on <a href="https://calendly.com/me-zhyncs/30min" class="text-sky-500 hover:underline">Calendly</a>. I will decide whether to proceed based on the circumstances. Thank you for understanding.
                </p>

                <!-- Projects -->
                <h2 class="text-xl font-[550] mt-8 mb-4 text-sky-600">Projects</h2>
                <div class="pl-5 pr-2 mb-4">
                    <p class="mb-2">
                        <a href="https://github.com/sgl-project/sglang" class="font-semibold text-sky-500 hover:underline">SGLang</a>: SGLang is a fast serving framework for large language models and vision language models, which has been adopted by <em><strong><a href="https://www.amd.com" class="text-sky-500 hover:underline">AMD</a></strong></em> and <em><strong><a href="https://x.ai" class="text-sky-500 hover:underline">xAI</a></strong></em>.
                    </p>
                    <p>
                        <a href="https://github.com/flashinfer-ai/flashinfer" class="font-semibold text-sky-500 hover:underline">FlashInfer</a>: FlashInfer is a library and kernel generator for Large Language Models that provides high-performance implementation of LLM GPU kernels, which has been adopted by <em><strong><a href="https://github.com/sgl-project/sglang" class="text-sky-500 hover:underline">SGLang</a></strong></em>, <em><strong><a href="https://github.com/vllm-project/vllm" class="text-sky-500 hover:underline">vLLM</a></strong></em> and <em><strong><a href="https://github.com/mlc-ai/mlc-llm" class="text-sky-500 hover:underline">MLC LLM</a></strong></em>.
                    </p>
                </div>

                <!-- Experience -->
                <h2 class="text-xl font-[550] mt-8 mb-4 text-sky-600">Experience</h2>
                <div class="pl-5 pr-2">
                    <p class="mb-4"><strong>Baseten</strong><br>Lead Software Engineer<br><em>Model Performance Team</em><br>September 2024 - now</p>
                    <p class="mb-4"><strong>LMSYS Org</strong><br>Team Member<br>July 2024 - now</p>
                    <p class="mb-4"><strong>Meituan</strong><br>Senior Software Engineer<br><em>Machine Learning Engine Group</em><br>August 2021 - July 2024</p>
                    <p class="mb-4"><strong>Baidu</strong><br>Software Engineer<br><em>Baidu Speech</em><br>June 2020 - August 2021</p>
                    <p class="mb-4"><strong>Stealth Startup</strong><br>Software Engineer<br>July 2019 - June 2020</p>
                </div>

                <!-- Education -->
                <h2 class="text-xl font-[550] mt-8 mb-4 text-sky-600">Education</h2>
                <div class="pl-5 pr-2">
                    <p class="mb-4"><strong>Jiangnan University</strong><br>Bachelor of Engineering<br>September 2015 - June 2019</p>
                </div>

                <!-- Publications -->
                <h2 class="text-xl font-[550] mt-8 mb-4 text-sky-600">Publications</h2>
                <ol class="list-none p-0 mt-0 space-y-4 pl-5 pr-2">
                    <li class="mb-4">
                        <div class="font-semibold">Locality-aware Fair Scheduling in LLM Serving</div>
                        <div class="text-gray-700">Shiyi Cao*, Yichuan Wang*, Ziming Mao, Pin-Lun Hsu, Liangsheng Yin, Tian Xia, Dacheng Li, Shu Liu, <strong>Yineng Zhang</strong>, Yang Zhou, Ying Sheng, Joseph Gonzalez, Ion Stoica</div>
                        <div>*indicates equal contribution</div>
                        <div class="mt-2"><a href="https://www.arxiv.org/abs/2501.14312" class="text-sky-500 hover:underline">Paper</a></div>
                    </li>
                    <li class="mb-4">
                        <div class="font-semibold">FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving</div>
                        <div class="text-gray-700">Zihao Ye, Lequn Chen, Ruihang Lai, Wuwei Lin, <strong>Yineng Zhang</strong>, Stephanie Wang, Tianqi Chen, Baris Kasikci, Vinod Grover, Arvind Krishnamurthy, Luis Ceze</div>
                        <div class="italic"><strong>MLSys 2025<br><a href="https://github.com/flashinfer-ai/flashinfer" class="text-sky-500 hover:underline">FlashInfer</a> has been adopted by SGLang, vLLM and MLC LLM.</strong></div>
                        <div class="mt-2"><a href="https://arxiv.org/abs/2501.01005" class="text-sky-500 hover:underline">Paper</a></div>
                    </li>
                    <li class="mb-4">
                        <div class="font-semibold">QQQ: Quality Quattuor-Bit Quantization for Large Language Models</div>
                        <div class="text-gray-700">Ying Zhang, Peng Zhang, Mincong Huang, Jingyang Xiang, Yujie Wang, Chao Wang, <strong>Yineng Zhang</strong>, Lei Yu, Chuan Liu, Wei Lin</div>
                        <div class="italic"><strong>QQQ has been adopted by <a href="https://github.com/vllm-project/vllm/pull/5218" class="text-sky-500 hover:underline">vLLM</a> and <a href="https://github.com/pytorch/ao/pull/1113" class="text-sky-500 hover:underline">torchao</a>.</strong></div>
                        <div class="mt-2"><a href="https://arxiv.org/abs/2406.09904" class="text-sky-500 hover:underline">Paper</a></div>
                    </li>
                </ol>
            </div>
        </main>

        
    </div>
</body>
</html>